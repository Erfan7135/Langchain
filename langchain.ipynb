{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Erfan7135/Langchain/blob/main/langchain.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New section"
      ],
      "metadata": {
        "id": "3dms01SYCKLJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9oPj7CffVQLH",
        "outputId": "e212dd67-17f0-4a59-aeea-dbec96a97d6e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.11.13\n"
          ]
        }
      ],
      "source": [
        "!python --version"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "installing necessary packages"
      ],
      "metadata": {
        "id": "Atj5TGHUVdPG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q langchain langchain-google-genai google-generativeai==0.8.5"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JRjxfl1hVbx2",
        "outputId": "52cf41fd-2f28-47cc-f089-436beedcebdc"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/42.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m \u001b[32m41.0/42.0 kB\u001b[0m \u001b[31m90.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m \u001b[32m41.0/42.0 kB\u001b[0m \u001b[31m90.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m \u001b[32m41.0/42.0 kB\u001b[0m \u001b[31m90.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.0/42.0 kB\u001b[0m \u001b[31m238.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Verify Installation"
      ],
      "metadata": {
        "id": "FAbtMsOpWhi9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip show google-generativeai google-ai-generativelanguage langchain-google-genai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bsLAU-ahWjhT",
        "outputId": "abe83070-aaa7-476a-df4f-4ab4b72a23c9",
        "collapsed": true
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name: google-generativeai\n",
            "Version: 0.8.5\n",
            "Summary: Google Generative AI High level API client library and tools.\n",
            "Home-page: https://github.com/google/generative-ai-python\n",
            "Author: Google LLC\n",
            "Author-email: googleapis-packages@google.com\n",
            "License: Apache 2.0\n",
            "Location: /usr/local/lib/python3.11/dist-packages\n",
            "Requires: google-ai-generativelanguage, google-api-core, google-api-python-client, google-auth, protobuf, pydantic, tqdm, typing-extensions\n",
            "Required-by: langchain-google-genai\n",
            "---\n",
            "Name: google-ai-generativelanguage\n",
            "Version: 0.6.15\n",
            "Summary: Google Ai Generativelanguage API client library\n",
            "Home-page: https://github.com/googleapis/google-cloud-python/tree/main/packages/google-ai-generativelanguage\n",
            "Author: Google LLC\n",
            "Author-email: googleapis-packages@google.com\n",
            "License: Apache 2.0\n",
            "Location: /usr/local/lib/python3.11/dist-packages\n",
            "Requires: google-api-core, google-auth, proto-plus, protobuf\n",
            "Required-by: google-generativeai\n",
            "---\n",
            "Name: langchain-google-genai\n",
            "Version: 2.0.10\n",
            "Summary: An integration package connecting Google's genai package and LangChain\n",
            "Home-page: https://github.com/langchain-ai/langchain-google\n",
            "Author: \n",
            "Author-email: \n",
            "License: MIT\n",
            "Location: /usr/local/lib/python3.11/dist-packages\n",
            "Requires: filetype, google-generativeai, langchain-core, pydantic\n",
            "Required-by: \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import Neccessary Files"
      ],
      "metadata": {
        "id": "JDO_YRyvXyQb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import langchain\n",
        "import langchain_google_genai\n",
        "print(\"LangChain and Gemini integration installed successfully!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "83PXIo2PXodh",
        "outputId": "b2480f0f-61d1-43d6-d13c-7136c838e70f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LangChain and Gemini integration installed successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import gemini key"
      ],
      "metadata": {
        "id": "bExbQIJ2Z3IN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "api_key = userdata.get('gemini_api')\n",
        "# print(api_key)"
      ],
      "metadata": {
        "id": "fhH0slqnZ6GV"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Initialized with langchain"
      ],
      "metadata": {
        "id": "v6ds_lm8aIh7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "#Initialize the model\n",
        "llm = ChatGoogleGenerativeAI(\n",
        "    model = \"gemini-2.0-flash\",\n",
        "    google_api_key = api_key,\n",
        "    temparature = 0.7 # 0=deterministic, 1= random\n",
        ")"
      ],
      "metadata": {
        "id": "0RPVqVFYaLHa"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Send Queries to verify setup"
      ],
      "metadata": {
        "id": "x2xNtyY_bAGZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = llm.invoke(\"Hello, What is langchain?\")\n",
        "print(response.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9LRuom_JbDVh",
        "outputId": "f111fc80-101f-417e-f05f-78891890a7b0"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Langchain is a framework designed to simplify the development of applications using large language models (LLMs). Think of it as a toolbox filled with components and interfaces that make it easier to connect LLMs to other data sources and interact with the environment.\n",
            "\n",
            "Here's a breakdown of what makes Langchain useful:\n",
            "\n",
            "**Key Concepts and Features:**\n",
            "\n",
            "*   **Components:** Langchain provides modular components that can be easily swapped in and out. These components include:\n",
            "    *   **Models:**  Interfaces to various LLMs (like GPT-3, PaLM, Llama 2, etc.) and text embedding models.  This allows you to easily switch between models without rewriting your entire application.\n",
            "    *   **Prompts:** Tools for creating and managing prompts.  This includes prompt templates, example selectors, and output parsers to structure LLM input and output effectively.\n",
            "    *   **Chains:**  Sequences of calls to LLMs or other utilities. Chains allow you to string together multiple operations, such as summarizing a document and then answering questions about the summary.  A very common use case.\n",
            "    *   **Indexes (Data Connection):**  Structures for organizing and retrieving data for LLMs to use.  This includes document loaders, text splitters, vectorstores (like Chroma, Pinecone, Weaviate), and retrieval methods.  This is how you give your LLM access to external knowledge.\n",
            "    *   **Memory:**  Modules for adding state to chains and agents. This allows the LLM to remember previous interactions and use that information to inform future responses.  Essential for conversational applications.\n",
            "    *   **Agents:**  Systems that use an LLM to decide which actions to take.  Agents can use tools to interact with the outside world, such as searching the internet, running code, or accessing databases.  They are like \"reasoning engines\" that can plan and execute complex tasks.\n",
            "    *   **Callbacks:** System that lets you hook into various stages of your LLM application. This includes logging, monitoring, streaming, and other tasks.\n",
            "\n",
            "*   **Chains (Composable Sequences):**  Langchain excels at creating chains of operations.  Imagine needing to:\n",
            "    1.  Retrieve relevant documents from a database.\n",
            "    2.  Summarize those documents using an LLM.\n",
            "    3.  Answer a user's question based on the summary.\n",
            "\n",
            "    Langchain makes it easy to define and execute this entire process as a single chain.\n",
            "\n",
            "*   **Agents (Decision Making):**  Agents are a more advanced concept.  They use an LLM to intelligently decide what actions to take based on the user's input and the available tools.  For example, an agent could:\n",
            "    1.  Receive a user request: \"What's the weather in London and then book me a flight to the nearest airport.\"\n",
            "    2.  Use a weather API tool to get the weather in London.\n",
            "    3.  Use a flight booking API tool to find and book a flight.\n",
            "    4.  Respond to the user with the weather and flight details.\n",
            "\n",
            "*   **Integration and Ecosystem:** Langchain integrates with a wide range of tools and services, including vector databases, APIs, and other LLM-related libraries.  This allows you to build complex applications that leverage the best of the LLM ecosystem.\n",
            "\n",
            "**Why Use Langchain?**\n",
            "\n",
            "*   **Rapid Prototyping:**  It speeds up the development process by providing pre-built components and abstractions.\n",
            "*   **Modularity and Flexibility:**  You can easily customize and extend Langchain to fit your specific needs.\n",
            "*   **Abstraction:** Simplifies interaction with LLMs and other services, removing the need to write boilerplate code.\n",
            "*   **Community and Support:**  Langchain has a large and active community, providing ample resources and support.\n",
            "*   **Focus on Use Cases:**  Langchain provides specific chains and agents designed for common use cases, such as question answering, summarization, and data augmentation.\n",
            "\n",
            "**Common Use Cases:**\n",
            "\n",
            "*   **Question Answering:**  Building chatbots that can answer questions based on a knowledge base.\n",
            "*   **Summarization:**  Summarizing long documents or articles.\n",
            "*   **Chatbots:**  Creating conversational agents that can interact with users in a natural and engaging way.\n",
            "*   **Data Augmentation:**  Generating synthetic data to improve the performance of machine learning models.\n",
            "*   **Code Generation:**  Generating code snippets or entire programs based on natural language descriptions.\n",
            "*   **Agentic Systems:** Building autonomous agents that can perform complex tasks.\n",
            "\n",
            "**In Simple Terms:**\n",
            "\n",
            "Langchain is like the \"React\" or \"Angular\" of the LLM world. It provides a structured way to build complex applications that leverage the power of large language models, simplifying the process and making it more accessible to developers. It provides the building blocks to connect language models to your data and let them interact with the world.\n",
            "\n",
            "**To get started:**\n",
            "\n",
            "*   Visit the official Langchain documentation: [https://www.langchain.com/](https://www.langchain.com/)\n",
            "*   Explore the Langchain tutorials and examples.\n",
            "*   Install the Langchain library using `pip install langchain`\n",
            "\n",
            "By using Langchain, developers can focus on building innovative and valuable applications instead of getting bogged down in the low-level details of interacting with LLMs.\n"
          ]
        }
      ]
    }
  ]
}